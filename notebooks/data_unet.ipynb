{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from scipy import ndimage as ndi\n",
    "import skimage as skim\n",
    "from skimage import feature\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "import pickle as pkl\n",
    "\n",
    "# Load mre data\n",
    "full_data_dir = '/pghbio/dbmi/batmanlab/bpollack/predictElasticity/data/MRE/'\n",
    "ds = pkl.load(open(full_data_dir+'mre_ds_transform_2.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:   (sequence: 10, slices: 4, subject: 20, x: 256, y: 256)\n",
       "Coordinates:\n",
       "  * subject   (subject) <U3 '365' '368' '370' '371' ... '403' '404' '405' '406'\n",
       "  * sequence  (sequence) <U8 'T2SS' 'T1Pre' 'T1Pos' ... 'extra3' 'extra4'\n",
       "Dimensions without coordinates: slices, x, y\n",
       "Data variables:\n",
       "    images    (subject, sequence, slices, y, x) float64 0.0 0.0 0.0 ... 0.0 0.0\n",
       "    ages      (subject) int64 58 60 58 74 73 64 38 76 ... 70 37 63 63 56 44 50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'sequence' (sequence: 10)>\n",
      "array(['T2SS', 'T1Pre', 'T1Pos', 'T2FR', 'elastMsk', 'elast', 'msk', 'extra2',\n",
      "       'extra3', 'extra4'], dtype='<U8')\n",
      "Coordinates:\n",
      "  * sequence  (sequence) <U8 'T2SS' 'T1Pre' 'T1Pos' ... 'extra3' 'extra4'\n",
      "<xarray.DataArray 'subject' ()>\n",
      "array('365', dtype='<U3')\n",
      "Coordinates:\n",
      "    subject  <U3 '365'\n"
     ]
    }
   ],
   "source": [
    "print(ds.sequence)\n",
    "print(ds.subject[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_ds_vis(torch_ds, index):\n",
    "    fig, axes = plt.subplots(4, 4, constrained_layout=True, figsize=(10,10), sharex=True, sharey=True)\n",
    "    for cols in axes:\n",
    "        for cell in cols:\n",
    "            axes[cols][cell].imshow(torch_ds[cols][cell])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use xArray to define the dataset.  Easy to query and map (although might not be fast when scaling up)\n",
    "input_example = ds.sel(sequence=['T2SS', 'T1Pre', 'T1Pos', 'T2FR']).images\n",
    "target_example = ds.sel(sequence=['elast']).images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4, 4, 256, 256)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 18, 'val': 2}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "# need data to be ordered thusly:\n",
    "# image_sequence,width,hight,depth\n",
    "class MREDataset(Dataset):\n",
    "    def __init__(self, xa_ds, set_type='train', transform=None):\n",
    "        subjects = xa_ds.subject\n",
    "        inputs = ['T2SS', 'T1Pre', 'T1Pos', 'T2FR']\n",
    "        targets = ['elast']\n",
    "        if set_type == 'train':\n",
    "            subjects = subjects[:-2]\n",
    "        elif set_type == 'val':\n",
    "            subjects = subjects[-2:]\n",
    "        else:\n",
    "            raise AttributeError('Must choose one of [\"train\", \"val\"] for `set_type`.')\n",
    "        #self.subject_dict = dict(zip(range(len(subjects), subjects )))\n",
    "        \n",
    "        self.input_images = xa_ds.sel(sequence=inputs, subject=subjects).transpose(\n",
    "            'subject', 'sequence', 'x', 'y', 'slices').images.values\n",
    "        self.target_images = xa_ds.sel(sequence=targets, subject=subjects).transpose(\n",
    "            'subject', 'sequence', 'x', 'y', 'slices').images.values\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        target = self.target_images[idx]\n",
    "        if self.transform:\n",
    "            image = torch.Tensor(self.transform(image))\n",
    "            target = torch.Tensor(self.transform(target))\n",
    "        \n",
    "        return [image, target]\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "#trans = transforms.Compose([\n",
    "#   torch.Tensor(),\n",
    "#])\n",
    "trans=None\n",
    "\n",
    "train_set = MREDataset(ds, set_type='train', transform = trans)\n",
    "val_set = MREDataset(ds, set_type='val', transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 256, 256, 4])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, targets= next(iter(dataloaders['train']))\n",
    "\n",
    "#print(inputs.shape, masks.shape)\n",
    "#for x in [inputs.numpy(), masks.numpy()]:\n",
    "#    print(x.min(), x.max(), x.mean(), x.std())\n",
    "print(inputs.shape)\n",
    "\n",
    "#torch_ds_vis(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-15          [-1, 256, 28, 28]               0\n",
      "           Conv2d-16          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-17          [-1, 512, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "         Upsample-20          [-1, 512, 56, 56]               0\n",
      "           Conv2d-21          [-1, 256, 56, 56]       1,769,728\n",
      "             ReLU-22          [-1, 256, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-24          [-1, 256, 56, 56]               0\n",
      "         Upsample-25        [-1, 256, 112, 112]               0\n",
      "           Conv2d-26        [-1, 128, 112, 112]         442,496\n",
      "             ReLU-27        [-1, 128, 112, 112]               0\n",
      "           Conv2d-28        [-1, 128, 112, 112]         147,584\n",
      "             ReLU-29        [-1, 128, 112, 112]               0\n",
      "         Upsample-30        [-1, 128, 224, 224]               0\n",
      "           Conv2d-31         [-1, 64, 224, 224]         110,656\n",
      "             ReLU-32         [-1, 64, 224, 224]               0\n",
      "           Conv2d-33         [-1, 64, 224, 224]          36,928\n",
      "             ReLU-34         [-1, 64, 224, 224]               0\n",
      "           Conv2d-35          [-1, 6, 224, 224]             390\n",
      "================================================================\n",
      "Total params: 7,783,238\n",
      "Trainable params: 7,783,238\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 454.02\n",
      "Params size (MB): 29.69\n",
      "Estimated Total Size (MB): 484.28\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpollack/conda_envs/mre/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_unet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = pytorch_unet.UNet(6)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/39\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpollack/conda_envs/mre/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/bpollack/conda_envs/mre/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bce: 0.227722, dice: 0.993783, loss: 0.610752\n",
      "val: bce: 0.026737, dice: 0.969505, loss: 0.498121\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 1/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.022401, dice: 0.789227, loss: 0.405814\n",
      "val: bce: 0.026967, dice: 0.670523, loss: 0.348745\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 2/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.026391, dice: 0.570979, loss: 0.298685\n",
      "val: bce: 0.022720, dice: 0.458770, loss: 0.240745\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 3/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.017827, dice: 0.413812, loss: 0.215819\n",
      "val: bce: 0.014746, dice: 0.377296, loss: 0.196021\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 4/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.012895, dice: 0.315185, loss: 0.164040\n",
      "val: bce: 0.010348, dice: 0.237765, loss: 0.124057\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 5/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.009704, dice: 0.222685, loss: 0.116194\n",
      "val: bce: 0.008657, dice: 0.193178, loss: 0.100918\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 6/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.009053, dice: 0.210272, loss: 0.109663\n",
      "val: bce: 0.008518, dice: 0.198778, loss: 0.103648\n",
      "0m 43s\n",
      "Epoch 7/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.007619, dice: 0.182249, loss: 0.094934\n",
      "val: bce: 0.007896, dice: 0.161274, loss: 0.084585\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 8/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.007253, dice: 0.171236, loss: 0.089244\n",
      "val: bce: 0.007332, dice: 0.145428, loss: 0.076380\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 9/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.005195, dice: 0.118274, loss: 0.061735\n",
      "val: bce: 0.004896, dice: 0.106747, loss: 0.055822\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 10/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.004007, dice: 0.077172, loss: 0.040590\n",
      "val: bce: 0.003741, dice: 0.068482, loss: 0.036112\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 11/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003799, dice: 0.069497, loss: 0.036648\n",
      "val: bce: 0.003614, dice: 0.062090, loss: 0.032852\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 12/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003444, dice: 0.060801, loss: 0.032123\n",
      "val: bce: 0.003333, dice: 0.057280, loss: 0.030307\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 13/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003320, dice: 0.058104, loss: 0.030712\n",
      "val: bce: 0.003271, dice: 0.054917, loss: 0.029094\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 14/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003048, dice: 0.053267, loss: 0.028158\n",
      "val: bce: 0.002744, dice: 0.049876, loss: 0.026310\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 15/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002938, dice: 0.055778, loss: 0.029358\n",
      "val: bce: 0.002778, dice: 0.050502, loss: 0.026640\n",
      "0m 43s\n",
      "Epoch 16/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002636, dice: 0.049097, loss: 0.025866\n",
      "val: bce: 0.002918, dice: 0.047687, loss: 0.025303\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 17/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002541, dice: 0.048014, loss: 0.025278\n",
      "val: bce: 0.002589, dice: 0.044018, loss: 0.023303\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 18/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002368, dice: 0.043845, loss: 0.023107\n",
      "val: bce: 0.002537, dice: 0.043157, loss: 0.022847\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 19/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002415, dice: 0.045893, loss: 0.024154\n",
      "val: bce: 0.002451, dice: 0.045829, loss: 0.024140\n",
      "0m 43s\n",
      "Epoch 20/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002140, dice: 0.041307, loss: 0.021724\n",
      "val: bce: 0.002583, dice: 0.041988, loss: 0.022286\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 21/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002108, dice: 0.040204, loss: 0.021156\n",
      "val: bce: 0.002216, dice: 0.038945, loss: 0.020581\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 22/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003132, dice: 0.059450, loss: 0.031291\n",
      "val: bce: 0.004341, dice: 0.068656, loss: 0.036499\n",
      "0m 43s\n",
      "Epoch 23/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002387, dice: 0.046703, loss: 0.024545\n",
      "val: bce: 0.002252, dice: 0.041675, loss: 0.021964\n",
      "0m 43s\n",
      "Epoch 24/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001976, dice: 0.039627, loss: 0.020801\n",
      "val: bce: 0.002138, dice: 0.039521, loss: 0.020829\n",
      "0m 43s\n",
      "Epoch 25/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001869, dice: 0.036911, loss: 0.019390\n",
      "val: bce: 0.002161, dice: 0.038434, loss: 0.020298\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 26/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001826, dice: 0.036177, loss: 0.019002\n",
      "val: bce: 0.002111, dice: 0.038132, loss: 0.020121\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 27/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001800, dice: 0.035802, loss: 0.018801\n",
      "val: bce: 0.002092, dice: 0.037795, loss: 0.019943\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 28/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001779, dice: 0.035510, loss: 0.018644\n",
      "val: bce: 0.002067, dice: 0.037758, loss: 0.019913\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 29/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001770, dice: 0.035244, loss: 0.018507\n",
      "val: bce: 0.002063, dice: 0.037532, loss: 0.019797\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 30/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001751, dice: 0.035029, loss: 0.018390\n",
      "val: bce: 0.002100, dice: 0.037505, loss: 0.019803\n",
      "0m 43s\n",
      "Epoch 31/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001733, dice: 0.034743, loss: 0.018238\n",
      "val: bce: 0.002074, dice: 0.037384, loss: 0.019729\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 32/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001729, dice: 0.034534, loss: 0.018132\n",
      "val: bce: 0.001991, dice: 0.037151, loss: 0.019571\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 33/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001713, dice: 0.034334, loss: 0.018023\n",
      "val: bce: 0.002000, dice: 0.036964, loss: 0.019482\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 34/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001683, dice: 0.034119, loss: 0.017901\n",
      "val: bce: 0.001968, dice: 0.036791, loss: 0.019380\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 35/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001699, dice: 0.033881, loss: 0.017790\n",
      "val: bce: 0.002015, dice: 0.036797, loss: 0.019406\n",
      "0m 43s\n",
      "Epoch 36/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001677, dice: 0.033761, loss: 0.017719\n",
      "val: bce: 0.001964, dice: 0.036828, loss: 0.019396\n",
      "0m 43s\n",
      "Epoch 37/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001649, dice: 0.033471, loss: 0.017560\n",
      "val: bce: 0.001954, dice: 0.036315, loss: 0.019135\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 38/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001651, dice: 0.033259, loss: 0.017455\n",
      "val: bce: 0.001917, dice: 0.036448, loss: 0.019183\n",
      "0m 43s\n",
      "Epoch 39/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001625, dice: 0.033089, loss: 0.017357\n",
      "val: bce: 0.001952, dice: 0.036132, loss: 0.019042\n",
      "saving best model\n",
      "0m 43s\n",
      "Best val loss: 0.019042\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 6\n",
    "\n",
    "model = pytorch_unet.UNet(num_class).to(device)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpollack/conda_envs/mre/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 192, 192)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
