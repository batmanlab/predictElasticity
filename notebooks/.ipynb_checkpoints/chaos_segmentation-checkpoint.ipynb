{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DICOM-Images\" data-toc-modified-id=\"DICOM-Images-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>DICOM Images</a></span></li><li><span><a href=\"#Nifti-Maker\" data-toc-modified-id=\"Nifti-Maker-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Nifti Maker</a></span></li><li><span><a href=\"#xarray-generation\" data-toc-modified-id=\"xarray-generation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>xarray generation</a></span></li><li><span><a href=\"#xarray-viewer\" data-toc-modified-id=\"xarray-viewer-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>xarray viewer</a></span></li><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Slurm-Analysis\" data-toc-modified-id=\"Slurm-Analysis-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Slurm Analysis</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "hv.extension('bokeh')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "\n",
    "from mre.plotting import patient_series_viewer, chaos_viewer, xr_viewer, hv_dl_vis_chaos\n",
    "from mre.preprocessing import make_nifti_atlas_v2, make_xr_dataset_for_chaos\n",
    "from mre.segmentation import ChaosDataset\n",
    "from mre.train_seg_model import train_seg_model \n",
    "from mre import pytorch_arch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.utils\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/pghbio/dbmi/batmanlab/bpollack/predictElasticity/data/CHAOS/Train_Sets/MR/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# patient_series_viewer(data_dir, 'DICOMA/PA1/ST0')\n",
    "# patient_series_viewer(data_dir, '1', img_type='DICOM_CHAOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nifti Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_nifti_atlas_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_series_viewer(data_dir, 'NIFTI/01', img_type='NIFTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chaos_viewer(data_dir, 'NIFTI/03')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/CHAOS/Train_Sets/MR/NIFTI/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients = [\"01\",  \"03\",  \"08\",  \"13\",  \"19\",  \"21\",  \"31\",  \"33\",  \"36\",  \"38\",\n",
    "# \"02\",  \"05\",  \"10\",  \"15\",  \"20\",  \"22\",  \"32\",  \"34\",  \"37\",  \"39\"] \n",
    "# ds = make_xr_dataset_for_chaos(patients, 256, 256, 32, 'chaos')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_path = Path(data_dir, 'xarray_chaos.nc')\n",
    "#ds = xr.open_dataset(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xr_viewer(ds, overlay_data='mask')\n",
    "#ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "out_dir = '/pghbio/dbmi/batmanlab/bpollack/predictElasticity/data/CHAOS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-01_10-11-11\n",
      "{'train_trans': True, 'train_clip': True, 'train_aug': False, 'train_sample': 'shuffle', 'val_trans': True, 'val_clip': True, 'val_aug': False, 'val_sample': 'shuffle', 'test_trans': True, 'test_clip': True, 'test_aug': False, 'train_seq_mode': None, 'val_seq_mode': None, 'test_seq_mode': 'all', 'def_seq_mode': 'random', 'seed': 100, 'subj': '01', 'batch_size': 4, 'model_cap': 32, 'lr': 0.03, 'step_size': 80, 'gamma': 0.1, 'num_epochs': 200, 'dry_run': False, 'coord_conv': False, 'loss': 'dice', 'model_arch': '3D', 'n_layers': 5, 'in_channels': 1, 'out_channels_final': 1, 'channel_growth': True, 'transfer_layer': False, 'bce_weight': 0.5, 'resize': False, 'transform': True, 'bc_weight': 0.2}\n",
      "<xarray.Dataset>\n",
      "Dimensions:   (sequence: 3, subject: 20, x: 256, y: 256, z: 32)\n",
      "Coordinates:\n",
      "  * subject   (subject) object '01' '03' '08' '13' '19' ... '32' '34' '37' '39'\n",
      "  * sequence  (sequence) object 't1_in' 't1_out' 't2'\n",
      "  * x         (x) int64 0 1 2 3 4 5 6 7 8 ... 248 249 250 251 252 253 254 255\n",
      "  * y         (y) int64 255 254 253 252 251 250 249 248 247 ... 7 6 5 4 3 2 1 0\n",
      "  * z         (z) int64 0 1 2 3 4 5 6 7 8 9 10 ... 22 23 24 25 26 27 28 29 30 31\n",
      "Data variables:\n",
      "    image     (subject, sequence, x, y, z) int16 ...\n",
      "    mask      (subject, sequence, x, y, z) int16 ...\n",
      "train:  16\n",
      "val:  3\n",
      "test:  1\n",
      "3d\n",
      "Let's use 4 GPUs!\n",
      "Epoch 0/199\n",
      "----------\n",
      "LR 0.03\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.91 GiB total capacity; 11.02 GiB already allocated; 63.06 MiB free; 284.07 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6c76887f6d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                          \u001b[0mmodel_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_growth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                          \u001b[0mmodel_cap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_seq_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                          bc_weight=0.2)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# model_path = Path(out_dir, 'trained_models', subj, f'model_{model_version}.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pghbio/dbmi/batmanlab/bpollack/predictElasticity/mre/train_seg_model.py\u001b[0m in \u001b[0;36mtrain_seg_model\u001b[0;34m(data_path, data_file, output_path, model_version, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         model, best_loss, best_dice, best_bce = train_model_core(\n\u001b[1;32m    169\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             tb_writer=writer, verbose=verbose, loss_func=loss)\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Write outputs and save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pghbio/dbmi/batmanlab/bpollack/predictElasticity/mre/train_seg_model.py\u001b[0m in \u001b[0;36mtrain_model_core\u001b[0;34m(model, optimizer, scheduler, device, dataloaders, num_epochs, loss_func, bce_weight, tb_writer, verbose)\u001b[0m\n\u001b[1;32m    277\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;31m# accrue total number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/new_mre/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/new_mre/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.91 GiB total capacity; 11.02 GiB already allocated; 63.06 MiB free; 284.07 MiB cached)"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "subj = '01'\n",
    "version = None\n",
    "# version = '2019-10-31_11-33-07'\n",
    "n_layers = 5\n",
    "model_cap = 16\n",
    "channel_growth = True\n",
    "seq_mode = 'random'\n",
    "model_arch='3D'\n",
    "now = datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "if version is None: version = now\n",
    "#model_version=f'chaos_notebook_test_{version}'\n",
    "model_version=version\n",
    "print(now)\n",
    "output = train_seg_model(data_dir, 'xarray_chaos.nc', out_dir, model_version=model_version, subj=subj, loss='dice', dry_run=False,\n",
    "                         transform=True, def_seq_mode=seq_mode, coord_conv=False, step_size=80, num_epochs=200, lr=3e-2, \n",
    "                         model_arch=model_arch, resize=False, n_layers=n_layers, channel_growth=channel_growth,\n",
    "                         model_cap=model_cap, batch_size=4, test_seq_mode='all', test_aug=False, train_aug=False, val_aug=False,\n",
    "                         bc_weight=0.2)\n",
    "\n",
    "# model_path = Path(out_dir, 'trained_models', subj, f'model_{model_version}.pkl')\n",
    "# model = pytorch_arch.GeneralUNet3D(n_layers, 1, model_cap, 1, channel_growth, False, False)\n",
    "# model_dict = torch.load(model_path, map_location='cpu')\n",
    "# model_dict = OrderedDict([(key[7:], val) for key, val in model_dict.items()])\n",
    "# model.load_state_dict(model_dict, strict=True)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(output) == 4:\n",
    "    inputs, targets, names, model = output\n",
    "else:\n",
    "    inputs, targets, names = next(iter(output[0]['test']))\n",
    "model_pred = None\n",
    "if model:\n",
    "    #inputs.to('cuda:0')\n",
    "    model_pred = torch.zeros_like(inputs)\n",
    "    for i in tqdm_notebook(range(inputs.shape[0])):\n",
    "        for j in tqdm_notebook(range(inputs.shape[1])):\n",
    "            model_pred[i, j, :] = model(inputs[i:i+1, j:j+1, :])\n",
    "            model_pred[i, j, :] = torch.sigmoid(model_pred[i, j, :])\n",
    "            # ones = torch.ones_like(model_pred[i, j, :])\n",
    "            # zeros = torch.zeros_like(model_pred[i, j, :])\n",
    "            # model_pred[:, i, :] = torch.where(model_pred[:, i, :]>3e-3, ones, zeros)\n",
    "    inputs.to('cpu')\n",
    "hv_dl_vis_chaos(inputs, targets, names, ['t1_in', 't1_out', 't2'], model_pred)\n",
    "# hv_dl_vis_chaos(inputs, targets, names, ['seq'], model_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slurm Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(out_dir, 'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for f in list(config_path.glob('*2019-10-03_12-10-03*.pkl')):\n",
    "    s_tmp = pd.Series(pd.read_pickle(str(f)), name=f.stem)\n",
    "    df = df.append(s_tmp, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test_dice_mean'] = (df.test_dice_t1_in+df.test_dice_t1_out+df.test_dice_t2)/3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.query('channel_growth==1').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "df2 = df.query('channel_growth==0').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "(df1.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='C Growth')*\n",
    "df2.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='C Static')).opts(legend_position='top_left', show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.query('def_seq_mode==\"t1_in\"').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "df2 = df.query('def_seq_mode==\"t1_out\"').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "df3 = df.query('def_seq_mode==\"t2\"').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "df4 = df.query('def_seq_mode==\"random\"').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "(df1.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight', 'job_name'], label='t1_in')*\n",
    "df2.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight', 'job_name'], label='t1_out')*\n",
    "df3.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight', 'job_name'], label='t2')*\n",
    "df4.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight', 'job_name'], label='random')\n",
    ").opts(legend_position='top_left', show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.query('bce_weight==0.2').sort_values('best_loss').reset_index().rename(columns={'index':'job_name'})\n",
    "df3 = df.query('bce_weight==0.5').sort_values('best_loss').reset_index().rename(columns={'index':'job_name'})\n",
    "df4 = df.query('bce_weight==0.8').sort_values('best_loss').reset_index().rename(columns={'index':'job_name'})\n",
    "(df1.hvplot.line(x='index', y='best_loss', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='0.2')*\n",
    "df3.hvplot.line(x='index', y='best_loss', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='0.5')*\n",
    "df4.hvplot.line(x='index', y='best_loss', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='0.8')\n",
    ").opts(legend_position='top_left', show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df0 = df.query('model_cap==4').sort_values('test_dice_mean').reset_index().rename(columns={'index':'job_name'})\n",
    "df1 = df.query('model_cap==8').sort_values('test_dice_mean').reset_index().rename(columns={'index':'job_name'})\n",
    "df2 = df.query('model_cap==12').sort_values('test_dice_mean').reset_index().rename(columns={'index':'job_name'})\n",
    "df3 = df.query('model_cap==16').sort_values('test_dice_mean').reset_index().rename(columns={'index':'job_name'})\n",
    "df4 = df.query('model_cap==32').sort_values('test_dice_mean').reset_index().rename(columns={'index':'job_name'})\n",
    "(df0.hvplot.line(x='index', y='test_dice_mean', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='4')*\n",
    "df1.hvplot.line(x='index', y='test_dice_mean', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='8')*\n",
    "df2.hvplot.line(x='index', y='test_dice_mean', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='12')*\n",
    "df3.hvplot.line(x='index', y='test_dice_mean', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='16')*\n",
    "df4.hvplot.line(x='index', y='test_dice_mean', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='32')\n",
    ").opts(legend_position='top_left', show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['model_cap', 'def_seq_mode'])['test_dice_t1_out'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: t1_out seems to outperform all other combos (including random).  Best current overall: t1_out, model_cap=8.  Why would adding additional images decrease performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.query('model_cap==8 and def_seq_mode==\"t1_out\" and subj==\"01\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.query('n_layers==5').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "df2 = df.query('n_layers==6').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "df3 = df.query('n_layers==7').sort_values('test_dice_t1_out').reset_index().rename(columns={'index':'job_name'})\n",
    "(df1.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='5')*\n",
    "df2.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='6')*\n",
    "df3.hvplot.line(x='index', y='test_dice_t1_out', hover_cols=['model_cap', 'def_seq_mode', 'bce_weight'], label='7')\n",
    ").opts(legend_position='top_left', show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
